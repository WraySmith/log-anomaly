{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# NOT SURE WHAT THE POINT OF THE CODE BELOW IS, REMOVE IF NOT NEEDED\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    torch.backends.cuda.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Mitch's error\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get data matrices and labels\n",
    "# train_data = np.load('../process/project_data/x_train_v1.npy')\n",
    "# read_train_labels = pd.read_csv('../process/project_data/y_train_v1.csv')\n",
    "# train_labels = read_train_labels['Label'] == 'Anomaly'\n",
    "# train_labels = train_labels.astype(int) # may not make sense to have an an int\n",
    "# test_data = np.load('../process/project_data/x_test_v1.npy')\n",
    "# read_test_labels = pd.read_csv('../process/project_data/y_test_v1.csv')\n",
    "# test_labels = read_test_labels['Label'] == 'Anomaly'\n",
    "# test_labels = test_labels.astype(int)\n",
    "\n",
    "\n",
    "data_loc = \"../../project_processed_data/\"\n",
    "\n",
    "# Train sets\n",
    "train_data = np.load('{}x_train_tf-idf_rolling_v2.npy'.format(data_loc))\n",
    "read_train_labels = pd.read_csv('{}y_train_tf-idf_rolling_v2.csv'.format(data_loc))\n",
    "train_labels = read_train_labels['Label'] == 'Anomaly'\n",
    "train_labels = train_labels.astype(int) # may not make sense to have an an int\n",
    "\n",
    "# Test sets\n",
    "test_data = np.load('{}x_val_tf-idf_rolling_v2.npy'.format(data_loc))\n",
    "read_test_labels = pd.read_csv('{}y_val_tf-idf_rolling_v2.csv'.format(data_loc))\n",
    "test_labels = read_test_labels['Label'] == 'Anomaly'\n",
    "test_labels = test_labels.astype(int)\n",
    "\n",
    "# data_dims = (19, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving to do the below code, we need to add a index reset on y_train and y_val \n",
    "\n",
    "# # Create val set\n",
    "# random.seed(10)\n",
    "\n",
    "# val_percent_size = 0.10\n",
    "# val_size = int(train_data.shape[0] * val_percent_size)\n",
    "# val_idx = random.sample(range(0, train_data.shape[0]), val_size)\n",
    "\n",
    "# # select the val sets based on random indexing\n",
    "# val_data = np.take(train_data, val_idx, axis=0)\n",
    "# val_labels = train_labels.iloc[val_idx]\n",
    "\n",
    "# # delete the val indexes from the train data\n",
    "# train_data = np.delete(train_data, val_idx, axis=0)\n",
    "# train_labels = train_labels.drop(train_labels.index[[val_idx]])\n",
    "\n",
    "# Val sets\n",
    "val_data = np.load('{}x_val_tf-idf_rolling_v2.npy'.format(data_loc))\n",
    "read_val_labels = pd.read_csv('{}y_train_tf-idf_rolling_v2.csv'.format(data_loc))\n",
    "val_labels = read_val_labels['Label'] == 'Anomaly'\n",
    "val_labels = val_labels.astype(int) # may not make sense to have an an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing on a subset\n",
    "sub_set_size = 10000 * 3\n",
    "train_data = train_data[0:sub_set_size]\n",
    "test_data = test_data[0:sub_set_size]\n",
    "val_data = val_data[0:sub_set_size]\n",
    "val_labels = val_labels[0:sub_set_size]\n",
    "train_labels = train_labels[0:sub_set_size]\n",
    "test_labels = test_labels[0:sub_set_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 19, 46)\n"
     ]
    }
   ],
   "source": [
    "data_dims = (train_data[1], train_data[2])\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,)\n",
      "0\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_labels[0])\n",
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = pd.get_dummies(train_labels)\n",
    "# train_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logDataset(Dataset):\n",
    "    \"\"\"Log Anomaly Features Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, data_vec, labels=None):\n",
    "        self.X = data_vec\n",
    "        self.y = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        data_matrix = self.X[idx]\n",
    "        \n",
    "        if not self.y is None:\n",
    "            return(data_matrix, self.y[idx])\n",
    "        else:\n",
    "            return data_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TRANSFORM CLASS DIDN\"T WORK, LEFT THIS IN JUST AS A REMINDER TO CONSIDER NORMALIZATION\n",
    "# AS WeLL AS THE COMMENT BELOW\n",
    "\n",
    "# NOTE THAT AS WE'VE DONE TF-IDF, WE MAY NOT WANT TO NORMALIZE\n",
    "# HOWEVER, ONE OF THE ODD THINGS HERE IS THAT SINCE WE'RE PASSING FILTERS OVER THINGS\n",
    "# IF THE COLUMNS REPRESENT SLIGHTLY DIFFERENT THINGS IT MAY BE AN ISSUE, ESPECIALLY FOR POOLING?\n",
    "# NORMALLY EACH PIXEL REPRESENTS THE EXACT SAME THING, NOT SURE IF THAT'S STILL THE CASE AFTER\n",
    "# TF-IDF\n",
    "\n",
    "# define transforms\n",
    "#train_mean = (0.5, 0.5, 0.5)\n",
    "#train_std = (0.5, 0.5, 0.5)\n",
    "\n",
    "#apply_transforms = transforms.Compose([#transforms.Resize((32, 32)), # probably not using this\n",
    "#                                        transforms.ToPILImage(), # believe this is required\n",
    "#                                        transforms.ToTensor(),\n",
    "#                                        #transforms.Normalize(train_mean, train_std),\n",
    "#                                        transforms.Pad((0, 0, 0, 1))]) # not sure if this is quite correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensort and pad matrixes to have dims of 20x48 instead of 19x48\n",
    "# Also need to add a dimension for conv2D\n",
    "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "train_data = F.pad(input=train_data, pad=(0, 0, 0, 1), mode='constant', value=0) # pad the bottom with 0s\n",
    "train_data = np.expand_dims(train_data, axis=1)\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "test_data = F.pad(input=test_data, pad=(0, 0, 0, 1), mode='constant', value=0)\n",
    "test_data = np.expand_dims(test_data, axis=1)\n",
    "val_data = torch.tensor(val_data, dtype=torch.float32)\n",
    "val_data = F.pad(input=val_data, pad=(0, 0, 0, 1), mode='constant', value=0)\n",
    "val_data = np.expand_dims(val_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1, 20, 46)"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1, 20, 46)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "# THESE ARE ALL STARTING POINTS BASED ON LAB3\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Architecture\n",
    "# NUM_FEATURES = data_dims[0] * data_dims[1] # not sure this is needed currently\n",
    "\n",
    "# not sure we should be using an architecture with 2 classes with softmax\n",
    "# doesn't it make more sense to have a single output node\n",
    "# previous labs/lectures have 2 classes with softmax which is somewhat confusing\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Other\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda:0\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass datasets into the custom dataclass\n",
    "train_dataset = logDataset(train_data, labels = train_labels)\n",
    "test_dataset = logDataset(test_data, labels = test_labels)\n",
    "val_dataset = logDataset(val_data, labels = val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a check that it worked\n",
    "# train_dataset.__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix batch dimensions: torch.Size([128, 1, 20, 46])\n",
      "Matrix label dimensions: torch.Size([128])\n",
      "Matrix batch dimensions: torch.Size([128, 1, 20, 46])\n",
      "Matrix label dimensions: torch.Size([128])\n",
      "Matrix batch dimensions: torch.Size([128, 1, 20, 46])\n",
      "Matrix label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# use DataLoader class\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_workers=0, # couldn't use workers https://github.com/fastai/fastbook/issues/85\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=0,\n",
    "                         shuffle=False)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=0,\n",
    "                         shuffle=False)\n",
    "\n",
    "\n",
    "# Checking the dataset\n",
    "for data, labels in train_loader:  \n",
    "    print('Matrix batch dimensions:', data.shape)\n",
    "    print('Matrix label dimensions:', labels.shape)\n",
    "    break\n",
    "\n",
    "# Checking the dataset\n",
    "for data, labels in test_loader:  \n",
    "    print('Matrix batch dimensions:', data.shape)\n",
    "    print('Matrix label dimensions:', labels.shape)\n",
    "    break\n",
    "    \n",
    "# Checking the dataset\n",
    "for data, labels in val_loader:  \n",
    "    print('Matrix batch dimensions:', data.shape)\n",
    "    print('Matrix label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 128\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 128\n"
     ]
    }
   ],
   "source": [
    "# this is something to do with warming up the nn\n",
    "# NEED TO FIGURE THIS OUT AND KEEP OR REMOVE\n",
    "device = torch.device(DEVICE)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(val_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "class logCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(logCNN, self).__init__()\n",
    "        # noticed that in many of the example models we're initializing weights and biases but\n",
    "        # not in the CNN example, check into this\n",
    "        self.num_classes = num_classes\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            # Selection of 16 and 32 based on discussion with Debangsha, use for now\n",
    "            # will need to figure out kernel size that works for dims and potentially add pooling\n",
    "            # need to figure out how to deal with non-square image\n",
    "            # goes in as 20x48\n",
    "            nn.Conv2d(1, 16, kernel_size=2),\n",
    "            # comes out as 19x47\n",
    "            nn.ReLU(),\n",
    "            #F.pad(pad=(0, 1, 0, 1), mode='constant', value=0), # may need to use this (won't work in sequential)\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # comes out as ???\n",
    "            nn.Conv2d(16, 32, kernel_size=2), # can also add padding directly into here (but is equal on either side) - (1, 2) 1 on left and right and 2 each above and below\n",
    "            nn.ReLU(),\n",
    "            #F.pad(pad=(0, 1, 0, 1), mode='constant', value=0), # may need to use this (won't work in sequential)\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            # NEED TO FIGURE OUT THE SIZE OF THE IMAGE\n",
    "            nn.Linear(1280, 120), # NEED TO DECIDE ON NUMBER OF NODES (120 BASED ON LAB3) ## NB changed to 1280 from 1408 based on error\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84), # NEED TO DECIDE ON NUMBER OF NODES (84 BASED ON LAB3)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, num_classes), # NOT SURE WE WANT TO BE USING 2 NODE OUTPUT\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "#         print(x.shape) # Was printing in the training logging\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1) # NOT SURE WE NEED SOFTMAX, POTENTIALLY SIGMOID?\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "## NOTE: WE MAY WANT TO CONSIDER USING DROPOUT AND L2 PENALTY; SEE LETURE 4 EXAMPLES FOR THIS\n",
    "## RELATIVELY EASY TO IMPLEMENT BUT MAY WANT TO CONSIDER ADDING VALIDATION SET SPLIT FROM THE TRAINING SET\n",
    "## WHEN DOING THIS AND PLOTTING THE VALIDATION/TRAINING COST FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = logCNN(NUM_CLASSES) # THIS WILL BE UPDATED IF NOT USING 2 OUTPUT NODES\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 0000/0235 | Cost: 0.7269\n",
      "Epoch: 001/010 | Batch 0050/0235 | Cost: 0.0778\n",
      "Epoch: 001/010 | Batch 0100/0235 | Cost: 0.0019\n",
      "Epoch: 001/010 | Batch 0150/0235 | Cost: 0.0336\n",
      "Epoch: 001/010 | Batch 0200/0235 | Cost: 0.0003\n",
      "Epoch: 001/010 | Train: 0.993%   | Val: 0.057%\n",
      "Time elapsed: 0.20 min\n",
      "Epoch: 002/010 | Batch 0000/0235 | Cost: 0.0021\n",
      "Epoch: 002/010 | Batch 0050/0235 | Cost: 0.0002\n",
      "Epoch: 002/010 | Batch 0100/0235 | Cost: 0.0001\n",
      "Epoch: 002/010 | Batch 0150/0235 | Cost: 0.0043\n",
      "Epoch: 002/010 | Batch 0200/0235 | Cost: 0.0004\n",
      "Epoch: 002/010 | Train: 0.991%   | Val: 0.057%\n",
      "Time elapsed: 0.39 min\n",
      "Epoch: 003/010 | Batch 0000/0235 | Cost: 0.0017\n",
      "Epoch: 003/010 | Batch 0050/0235 | Cost: 0.0001\n",
      "Epoch: 003/010 | Batch 0100/0235 | Cost: 0.0006\n",
      "Epoch: 003/010 | Batch 0150/0235 | Cost: 0.0004\n",
      "Epoch: 003/010 | Batch 0200/0235 | Cost: 0.0290\n",
      "Epoch: 003/010 | Train: 0.992%   | Val: 0.058%\n",
      "Time elapsed: 0.58 min\n",
      "Epoch: 004/010 | Batch 0000/0235 | Cost: 0.0005\n",
      "Epoch: 004/010 | Batch 0050/0235 | Cost: 0.0004\n",
      "Epoch: 004/010 | Batch 0100/0235 | Cost: 0.0001\n",
      "Epoch: 004/010 | Batch 0150/0235 | Cost: 0.0042\n",
      "Epoch: 004/010 | Batch 0200/0235 | Cost: 0.0002\n",
      "Epoch: 004/010 | Train: 0.992%   | Val: 0.057%\n",
      "Time elapsed: 0.77 min\n",
      "Epoch: 005/010 | Batch 0000/0235 | Cost: 0.0001\n",
      "Epoch: 005/010 | Batch 0050/0235 | Cost: 0.0001\n",
      "Epoch: 005/010 | Batch 0100/0235 | Cost: 0.0001\n",
      "Epoch: 005/010 | Batch 0150/0235 | Cost: 0.0000\n",
      "Epoch: 005/010 | Batch 0200/0235 | Cost: 0.0001\n",
      "Epoch: 005/010 | Train: 0.992%   | Val: 0.057%\n",
      "Time elapsed: 0.96 min\n",
      "Epoch: 006/010 | Batch 0000/0235 | Cost: 0.0006\n",
      "Epoch: 006/010 | Batch 0050/0235 | Cost: 0.0050\n",
      "Epoch: 006/010 | Batch 0100/0235 | Cost: 0.0000\n",
      "Epoch: 006/010 | Batch 0150/0235 | Cost: 0.0000\n",
      "Epoch: 006/010 | Batch 0200/0235 | Cost: 0.0001\n",
      "Epoch: 006/010 | Train: 0.993%   | Val: 0.057%\n",
      "Time elapsed: 1.17 min\n",
      "Epoch: 007/010 | Batch 0000/0235 | Cost: 0.0113\n",
      "Epoch: 007/010 | Batch 0050/0235 | Cost: 0.0001\n",
      "Epoch: 007/010 | Batch 0100/0235 | Cost: 0.0000\n",
      "Epoch: 007/010 | Batch 0150/0235 | Cost: 0.0000\n",
      "Epoch: 007/010 | Batch 0200/0235 | Cost: 0.0007\n",
      "Epoch: 007/010 | Train: 0.993%   | Val: 0.058%\n",
      "Time elapsed: 1.38 min\n",
      "Epoch: 008/010 | Batch 0000/0235 | Cost: 0.0000\n",
      "Epoch: 008/010 | Batch 0050/0235 | Cost: 0.0000\n",
      "Epoch: 008/010 | Batch 0100/0235 | Cost: 0.0000\n",
      "Epoch: 008/010 | Batch 0150/0235 | Cost: 0.0001\n",
      "Epoch: 008/010 | Batch 0200/0235 | Cost: 0.0000\n",
      "Epoch: 008/010 | Train: 0.993%   | Val: 0.057%\n",
      "Time elapsed: 1.57 min\n",
      "Epoch: 009/010 | Batch 0000/0235 | Cost: 0.0000\n",
      "Epoch: 009/010 | Batch 0050/0235 | Cost: 0.0000\n",
      "Epoch: 009/010 | Batch 0100/0235 | Cost: 0.0000\n",
      "Epoch: 009/010 | Batch 0150/0235 | Cost: 0.0000\n",
      "Epoch: 009/010 | Batch 0200/0235 | Cost: 0.0000\n",
      "Epoch: 009/010 | Train: 0.993%   | Val: 0.057%\n",
      "Time elapsed: 1.77 min\n",
      "Epoch: 010/010 | Batch 0000/0235 | Cost: 0.0011\n",
      "Epoch: 010/010 | Batch 0050/0235 | Cost: 0.0002\n",
      "Epoch: 010/010 | Batch 0100/0235 | Cost: 0.0000\n",
      "Epoch: 010/010 | Batch 0150/0235 | Cost: 0.0059\n",
      "Epoch: 010/010 | Batch 0200/0235 | Cost: 0.0004\n",
      "Epoch: 010/010 | Train: 0.993%   | Val: 0.057%\n",
      "Time elapsed: 1.96 min\n",
      "Total Training Time: 1.96 min\n"
     ]
    }
   ],
   "source": [
    "# NEED TO FIGURE OUT THE BEST FUNCTION FOR ACCURACY\n",
    "# NEED TO FOCUS ON TRUE/FALSE, NOT ON CLASSES\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(DEVICE)\n",
    "        \n",
    "        # NOTE TO SELF WHEN CHANGING INT TARGETS AT TOP OF NOTEBOOK, WILL ALSO HAVE TO CHANGE / REMOVE .long here\n",
    "        targets = targets.to(DEVICE, dtype=torch.long) # had to pass in to torch.long based on the 1, 0 int labels\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "\n",
    "# This needs to be vectorized\n",
    "def compute_f1(model, data_loader, device):\n",
    "    y_hats = []\n",
    "    y_acts = []\n",
    "    for i, (inputs, targets) in enumerate(data_loader):\n",
    "        yhat = model(inputs)[-1].cpu().detach().numpy().round()\n",
    "        yhat = np.argmax(yhat, axis=1)\n",
    "        y_hats.append(yhat)\n",
    "        y_acts.append(list(targets.cpu().detach().numpy()))\n",
    "    \n",
    "    y_hats = [item for sublist in y_hats for item in sublist]\n",
    "    y_acts = [item for sublist in y_acts for item in sublist]\n",
    "    return f1_score(y_acts, y_hats)\n",
    "\n",
    "  \n",
    "\n",
    "start_time = time.time()\n",
    "minibatch_cost = [] # this isn't in the CNN model example but is from lecture 3 example files\n",
    "epoch_train_performance = []\n",
    "epoch_val_performance = []\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE, dtype=torch.long) # another had to use torch.long\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets) # NEED TO MODIFY BASED ON BEST COST FUNCTION\n",
    "\n",
    "#         loss = criterion(logits, targets.unsqueeze(1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "#         loss.backward()\n",
    "        minibatch_cost.append(cost) # from lecture 3 example files\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING - MAY WANT TO MODIFY LOGGING INTERVALS\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost, ))\n",
    "\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        train_performance = compute_f1(model, train_loader, device=DEVICE)\n",
    "        val_performance = compute_f1(model, val_loader, device=DEVICE)\n",
    "        epoch_train_performance.append(train_performance) # from lecture 3 example files\n",
    "        epoch_val_performance.append(val_performance)\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%   | Val: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, train_performance, val_performance))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot cost functions\n",
    "minibatch_cost_cpu = [i.cpu().detach().numpy() for i in minibatch_cost]\n",
    "# epoch_cost_cpu = [i.cpu().detach().numpy() for i in epoch_performance]\n",
    "\n",
    "\n",
    "plt.plot(range(len(minibatch_cost_cpu)), minibatch_cost_cpu)\n",
    "plt.ylabel('Cost Function Label') # update this label after cost function selected\n",
    "plt.xlabel('Minibatch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(epoch_train_performance)), epoch_train_performance, label=\"train f1 scores\")\n",
    "plt.plot(range(len(epoch_val_performance)), epoch_val_performance, label=\"val f1 scores\")\n",
    "plt.ylabel('Accuracy') # update this label after cost function selected\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1_score: 0.43%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    # THIS NEEDS TO BE UPDATED BASED ON THE FUNCTION NAME WE'RE USING\n",
    "    print('Test f1_score: %.2f%%' % (compute_f1(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1_score: 0.99%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    # THIS NEEDS TO BE UPDATED BASED ON THE FUNCTION NAME WE'RE USING\n",
    "    print('Train f1_score: %.2f%%' % (compute_f1(model, train_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE NEED TO BE EXTENDING THE PERFORMANCE MEASURES TO INCLUDE THOSE USED IN THE PAPERS\n",
    "# F SCORE, PRECISION ETC ETC, MOST OF THE PAPERS SEEM TO USE SIMILAR METRICS, SHOULD BE RELATIVELY SIMPLE\n",
    "# AND COULD BE POTENTIALLY BUILD DIRECTLY INTO THE COST FUNCTION (THE FUNCTION COULD RETURN MULTIPLE PARAMS AND WE WOULD OBVIOUSLY JUST USE THE ONE WE NEEDED FOR MODEL TRAINING BUT THEN WE WOULD HAVE ACCESS TO ALL OF THEM INSTEAD OF WRITING ANOTHER FUNCTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALSO RECOMMEND SOME SORT OF VIS TOOL ON BEING ABLE TO LOOK AT A COUPLE OF THE TIME IMAGES THAT ARE LABELLED ANOMALOUS CORRECTLY AND ONES THAT ARE LABELLED ANOMLAOUS INCORRECTLY OR NORMAL INCORRECTLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050322580645161284\n"
     ]
    }
   ],
   "source": [
    "# Evaluate F1 score on test set\n",
    "y_hats = []\n",
    "y_acts = []\n",
    "for i, (inputs, targets) in enumerate(val_loader):\n",
    "    yhat = model(inputs)[-1].cpu().detach().numpy().round()\n",
    "    yhat = np.argmax(yhat, axis=1)\n",
    "    y_hats.append(yhat)\n",
    "    y_acts.append(list(targets.cpu().detach().numpy()))\n",
    "\n",
    "y_hats = [item for sublist in y_hats for item in sublist]\n",
    "y_acts = [item for sublist in y_acts for item in sublist]\n",
    "\n",
    "f1 = f1_score(y_acts, y_hats)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4603825136612022\n"
     ]
    }
   ],
   "source": [
    "# Evaluate F1 score on test set\n",
    "y_hats = []\n",
    "y_acts = []\n",
    "for i, (inputs, targets) in enumerate(test_loader):\n",
    "    yhat = model(inputs)[-1].cpu().detach().numpy().round()\n",
    "    yhat = np.argmax(yhat, axis=1)\n",
    "    y_hats.append(yhat)\n",
    "    y_acts.append(list(targets.cpu().detach().numpy()))\n",
    "    counter += 1\n",
    "\n",
    "y_hats = [item for sublist in y_hats for item in sublist]\n",
    "y_acts = [item for sublist in y_acts for item in sublist]\n",
    "\n",
    "f1 = f1_score(y_acts, y_hats)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06520267002031536\n"
     ]
    }
   ],
   "source": [
    "# What is the f1 score if we predict only 1's\n",
    "y_hats = []\n",
    "y_acts = []\n",
    "for i, (inputs, targets) in enumerate(test_loader):\n",
    "\n",
    "    y_act = list(targets.cpu().detach().numpy())\n",
    "    y_acts.append(y_act)\n",
    "\n",
    "\n",
    "y_acts = [item for sublist in y_acts for item in sublist]\n",
    "y_hats = len(y_acts) * [1]\n",
    "f1 = f1_score(y_acts, y_hats)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# What is the f1 score if we predict only 0's\n",
    "y_hats = []\n",
    "y_acts = []\n",
    "for i, (inputs, targets) in enumerate(test_loader):\n",
    "\n",
    "    y_act = list(targets.cpu().detach().numpy())\n",
    "    y_acts.append(y_act)\n",
    "\n",
    "\n",
    "y_acts = [item for sublist in y_acts for item in sublist]\n",
    "y_hats = len(y_acts) * [0]\n",
    "f1 = f1_score(y_acts, y_hats)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06745362563237772\n"
     ]
    }
   ],
   "source": [
    "# What is the f1 score if we guess randomly\n",
    "y_hats = []\n",
    "y_acts = []\n",
    "for i, (inputs, targets) in enumerate(test_loader):\n",
    "\n",
    "    y_act = list(targets.cpu().detach().numpy())\n",
    "    y_acts.append(y_act)\n",
    "\n",
    "y_acts = [item for sublist in y_acts for item in sublist]\n",
    "y_hats = [0]*5000 + [1]*5000\n",
    "random.shuffle(y_hats)\n",
    "\n",
    "f1 = f1_score(y_acts, y_hats)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
