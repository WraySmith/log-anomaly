{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0559c2285f1e1088f109c5c53748833ede7a8d5fbeb2d49ae3f94019f339cd05d",
   "display_name": "Python 3.8.8 64-bit ('gputorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from PIL import Image\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    torch.backends.cuda.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "#RANDOM_SEED = 1\n",
    "#LEARNING_RATE = 0.001\n",
    "#BATCH_SIZE = 128\n",
    "#NUM_EPOCHS = 10\n",
    "\n",
    "# Architecture\n",
    "#NUM_FEATURES = 32*32\n",
    "#NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda:0\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "#GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train = pd.read_csv('log_train.csv')\n",
    "df_test = pd.read_csv('log_test.csv')\n",
    "\n",
    "# get data matrix and labels\n",
    "train_data = df_train.iloc[:, 1:]\n",
    "train_labels = df_train.iloc[:, 0]\n",
    "test_data = df_test.iloc[:, 1:]\n",
    "test_labels = df_test.iloc[:, 0]\n",
    "\n",
    "data_dims = (19, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logDataset(Dataset):\n",
    "    \"\"\"Log Anomaly Features Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, data_vec, dims, labels=None, transforms=None):\n",
    "        self.X = data_vec\n",
    "        self.dims = dims\n",
    "        self.y = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        data_matrix = self.X.iloc[idx, :]\n",
    "        data_matrix = np.asarray(data_matrix).astype(np.float64).reshape(dims, 1)\n",
    "\n",
    "        if self.transforms:\n",
    "            data_matrix = self.transforms(data_matrix)\n",
    "        \n",
    "        if self.y:\n",
    "            return(data_matrix, self.y[i])\n",
    "        else:\n",
    "            return data_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THAT AS WE'VE DONE TF-IDF, WE MAY NOT WANT TO NORMALIZE\n",
    "# HOWEVER, ONE OF THE ODD THINGS HERE IS THAT SINCE WE'RE PASSING FILTERS OVER THINGS\n",
    "# IF THE COLUMNS REPRESENT SLIGHTLY DIFFERENT THINGS IT MAY BE AN ISSUE, ESPECIALLY FOR POOLING?\n",
    "\n",
    "# define transforms\n",
    "#train_mean = (0.5, 0.5, 0.5)\n",
    "#train_std = (0.5, 0.5, 0.5)\n",
    "\n",
    "apply_transforms = transforms.Compose([#transforms.Resize((32, 32)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       #transforms.Normalize(train_mean, train_std)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = logDataset(train_data, dims = data_dims, transforms = apply_transforms)\n",
    "test_dataset = logDataset(test_data, dims = data_dims, transforms = apply_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_workers=8,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=8,\n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for data, labels in train_loader:  \n",
    "    print('Image batch dimensions:', data.shape)\n",
    "    print('Image label dimensions:', data.shape)\n",
    "    break\n",
    "\n",
    "# Checking the dataset\n",
    "for data, labels in train_loader:  \n",
    "    print('Image batch dimensions:', data.shape)\n",
    "    print('Image label dimensions:', data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}