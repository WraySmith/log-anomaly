{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0559c2285f1e1088f109c5c53748833ede7a8d5fbeb2d49ae3f94019f339cd05d",
   "display_name": "Python 3.8.8 64-bit ('gputorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from PIL import Image\n",
    "\n",
    "# NOT SURE WHAT THE POINT OF THE CODE BELOW IS\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    torch.backends.cuda.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Architecture\n",
    "#NUM_FEATURES = 32*32\n",
    "NUM_CLASSES = 2 # not sure this is needed\n",
    "\n",
    "# Other\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda:0\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train = pd.read_csv('log_train.csv')\n",
    "df_test = pd.read_csv('log_test.csv')\n",
    "\n",
    "# get data matrix and labels\n",
    "train_data = df_train.iloc[:, 1:]\n",
    "train_labels = df_train.iloc[:, 0]\n",
    "test_data = df_test.iloc[:, 1:]\n",
    "test_labels = df_test.iloc[:, 0]\n",
    "\n",
    "data_dims = (19, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logDataset(Dataset):\n",
    "    \"\"\"Log Anomaly Features Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, data_vec, dims, labels=None, transforms=None):\n",
    "        self.X = data_vec\n",
    "        self.dims = dims\n",
    "        self.y = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        data_matrix = self.X.iloc[idx, :]\n",
    "        data_matrix = np.asarray(data_matrix).astype(np.float64).reshape(dims, 1)\n",
    "\n",
    "        if self.transforms:\n",
    "            data_matrix = self.transforms(data_matrix)\n",
    "        \n",
    "        if self.y:\n",
    "            return(data_matrix, self.y[i])\n",
    "        else:\n",
    "            return data_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THAT AS WE'VE DONE TF-IDF, WE MAY NOT WANT TO NORMALIZE\n",
    "# HOWEVER, ONE OF THE ODD THINGS HERE IS THAT SINCE WE'RE PASSING FILTERS OVER THINGS\n",
    "# IF THE COLUMNS REPRESENT SLIGHTLY DIFFERENT THINGS IT MAY BE AN ISSUE, ESPECIALLY FOR POOLING?\n",
    "\n",
    "# define transforms\n",
    "#train_mean = (0.5, 0.5, 0.5)\n",
    "#train_std = (0.5, 0.5, 0.5)\n",
    "\n",
    "apply_transforms = transforms.Compose([#transforms.Resize((32, 32)),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       #transforms.Normalize(train_mean, train_std)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = logDataset(train_data, dims = data_dims, transforms = apply_transforms)\n",
    "test_dataset = logDataset(test_data, dims = data_dims, transforms = apply_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_workers=8,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=8,\n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for data, labels in train_loader:  \n",
    "    print('Image batch dimensions:', data.shape)\n",
    "    print('Image label dimensions:', data.shape)\n",
    "    break\n",
    "\n",
    "# Checking the dataset\n",
    "for data, labels in train_loader:  \n",
    "    print('Image batch dimensions:', data.shape)\n",
    "    print('Image label dimensions:', data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is something to do with warming up the nn\n",
    "# NEED TO FIGURE THIS OUT AND KEEP OR REMOVE\n",
    "device = torch.device(DEVICE)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "class logCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.grayscale = grayscale\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(1, 16, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 32*in_channels, kernel_size=2),\n",
    "            nn.ReLU(), # should there be a ReLU here or not? there wasn't after the 2D pooling layer\n",
    "            #nn.MaxPool2d(kernel_size=3)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32*4*4, 120*in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120*in_channels, 84*in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84*in_channels, num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = logCNN(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  }
 ]
}