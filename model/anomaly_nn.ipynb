{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0559c2285f1e1088f109c5c53748833ede7a8d5fbeb2d49ae3f94019f339cd05d",
   "display_name": "Python 3.8.8 64-bit ('gputorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from PIL import Image # NOT SURE IF WE'RE USING THIS ONE\n",
    "\n",
    "# NOT SURE WHAT THE POINT OF THE CODE BELOW IS\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    torch.backends.cuda.deterministic = True"
   ]
  },
  {
   "source": [
    "## Load and Prepare Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train = pd.read_csv('log_train.csv')\n",
    "df_test = pd.read_csv('log_test.csv')\n",
    "\n",
    "# get data matrix and labels\n",
    "train_data = df_train.iloc[:, 1:]\n",
    "train_labels = df_train.iloc[:, 0]\n",
    "test_data = df_test.iloc[:, 1:]\n",
    "test_labels = df_test.iloc[:, 0]\n",
    "\n",
    "data_dims = (19, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logDataset(Dataset):\n",
    "    \"\"\"Log Anomaly Features Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, data_vec, dims, labels=None, transforms=None):\n",
    "        self.X = data_vec\n",
    "        self.dims = dims\n",
    "        self.y = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        data_matrix = self.X.iloc[idx, :]\n",
    "        data_matrix = np.asarray(data_matrix).astype(np.float64).reshape(dims, 1)\n",
    "\n",
    "        if self.transforms:\n",
    "            data_matrix = self.transforms(data_matrix)\n",
    "        \n",
    "        if self.y:\n",
    "            return(data_matrix, self.y[i])\n",
    "        else:\n",
    "            return data_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THAT AS WE'VE DONE TF-IDF, WE MAY NOT WANT TO NORMALIZE\n",
    "# HOWEVER, ONE OF THE ODD THINGS HERE IS THAT SINCE WE'RE PASSING FILTERS OVER THINGS\n",
    "# IF THE COLUMNS REPRESENT SLIGHTLY DIFFERENT THINGS IT MAY BE AN ISSUE, ESPECIALLY FOR POOLING?\n",
    "# NORMALLY EACH PIXEL REPRESENTS THE EXACT SAME THING, NOT SURE IF THAT'S STILL THE CASE AFTER\n",
    "# TF-IDF\n",
    "\n",
    "# define transforms\n",
    "#train_mean = (0.5, 0.5, 0.5)\n",
    "#train_std = (0.5, 0.5, 0.5)\n",
    "\n",
    "apply_transforms = transforms.Compose([#transforms.Resize((32, 32)), # probably not using this\n",
    "                                       transforms.ToTensor(),\n",
    "                                       #transforms.Normalize(train_mean, train_std)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use DataLoader\n",
    "\n",
    "train_dataset = logDataset(train_data, dims = data_dims, transforms = apply_transforms)\n",
    "test_dataset = logDataset(test_data, dims = data_dims, transforms = apply_transforms)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          num_workers=8,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=8,\n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for data, labels in train_loader:  \n",
    "    print('Image batch dimensions:', data.shape)\n",
    "    print('Image label dimensions:', data.shape)\n",
    "    break\n",
    "\n",
    "# Checking the dataset\n",
    "for data, labels in train_loader:  \n",
    "    print('Image batch dimensions:', data.shape)\n",
    "    print('Image label dimensions:', data.shape)\n",
    "    break"
   ]
  },
  {
   "source": [
    "## Setup Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "# THESE ARE ALL STARTING POINTS BASED ON LAB3\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = data_dims[0] * data_dims[1]\n",
    "# not sure we should be using an architecture with 2 classes with softmax\n",
    "# doesn't it make more sense to have a single output node\n",
    "# previous labs/lectures have 2 classes with softmax which is somewhat confusing\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Other\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda:0\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is something to do with warming up the nn\n",
    "# NEED TO FIGURE THIS OUT AND KEEP OR REMOVE\n",
    "device = torch.device(DEVICE)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "for epoch in range(2):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "class logCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        # removed super init here as not sure it's required\n",
    "        self.num_classes = num_classes\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            # Selection of 16 and 32 based on discussion with Debangsha, use for now\n",
    "            # will need to figure out kernel size that works for dims and potentially add pooling\n",
    "            # need to figure out how to deal with non-square image\n",
    "            nn.Conv2d(1, 16, kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=2),\n",
    "            nn.ReLU()\n",
    "            #nn.MaxPool2d(kernel_size=3) # maybe not using the last pooling layer as the size may be quite small\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            # NEED TO FIGURE OUT THE SIZE OF THE IMAGE FOR THE *4*4 part\n",
    "            nn.Linear(32*4*4, 120), # NEED TO DECIDE ON NUMBER OF NODES (120 BASED ON LAB3)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84), # NEED TO DECIDE ON NUMBER OF NODES (84 BASED ON LAB3)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, num_classes), # NOT SURE WE WANT TO BE USING 2 NODE OUTPUT\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1) # NOT SURE WE NEED SOFTMAX\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = logCNN(NUM_CLASSES) # THIS WILL BE UPDATED IF NOT USING 2 OUTPUT NODES\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "source": [
    "# Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO FIGURE OUT THE BEST FUNCTION FOR ACCURACY\n",
    "# NEED TO FOCUS ON TRUE/FALSE\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets) # NEED TO MODIFY BASED ON BEST COST FUNCTION\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING - MAY WANT TO MODIFY LOGGING INTERVALS\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "source": [
    "## Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    # THIS NEEDS TO BE UPDATED BASED ON THE FUNCTION NAME WE'RE USING\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE NEED TO BE EXTENDING THE PERFORMANCE MEASURES TO INCLUDE THOSE USED IN THE PAPERS\n",
    "# F SCORE, PRECISION ETC ETC, MOST OF THE PAPERS SEEM TO USE SIMILAR METRICS, SHOULD BE RELATIVELY SIMPLE\n",
    "# AND COULD BE POTENTIALLY BUILD DIRECTLY INTO THE COST FUNCTION (THE FUNCTION COULD RETURN MULTIPLE PARAMS AND WE WOULD OBVIOUSLY JUST USE THE ONE WE NEEDED FOR MODEL TRAINING BUT THEN WE WOULD HAVE ACCESS TO ALL OF THEM INSTEAD OF WRITING ANOTHER FUNCTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALSO RECOMMEND SOME SORT OF VIS TOOL ON BEING ABLE TO LOOK AT A COUPLE OF THE TIME IMAGES THAT ARE LABELLED ANOMALOUS CORRECTLY AND ONES THAT ARE LABELLED ANOMLAOUS INCORRECTLY OR NORMAL INCORRECTLY\n",
    "\n",
    "# MAY REQURIE PASSING THE THE TIME IMAGE TO PIL (IF THIS DIDN\"T NEED TO BE ALREADY DONE ABOVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}