# Process Folder

Contains code to extract features from the semi-structured log files produced by the files contained within the `parse` directory.

## Loglizer

The code in this directory borrows heavily from the [Loglizer](https://github.com/logpai/loglizer) project. Loglizer takes semi structured log files and turns them into a dataframe, with one column as the block ids and another column the block's events stored as a list. Then turns the event lists into a bag of words, with options for normalization and tf-idf, to be fed into a preditive model.

This repository takes Loglizer steps further by slicing the events list into multiple rows, effictivley creating a time-image. Each row in the original loglizer dataframe is turned into a 2 by 2 numpy array. For each time image pandas rolling function is applied with a window size of two. This gives each slice of the time window a context of what has already happened. The output data is three dimentional.

## Data and Scripts

- `process/data_processor.py`'s input data was generated by `parse/project_parser.py`. Specifically the files called by `data_processor.py` are `anomaly_label.csv` (unsplit y data), `HDFS_train.log_structured.csv` (x_train), and `HDFS_test.log_structured.csv` (x_test) located in the `parse/project_parsed` directory. Processed and split data is named like `x_train_version_number`, where the y data are saved as `.csv` and the x data are saved as `.npy`.
